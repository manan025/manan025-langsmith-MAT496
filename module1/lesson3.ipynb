{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Tracing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far in this module, we've taken a look at the traceable decorator, and how we can use it to set up tracing.\n",
    "\n",
    "In this lesson, we're going to look at alternative ways in which we can set up tracing, and when you should think about using these different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain and LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are using LangChain or LangGraph, all we need to do to set up tracing is to set a few environment variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T22:02:21.818664Z",
     "start_time": "2025-10-07T22:02:21.810354Z"
    }
   },
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry too much about our graph implementation here, you can learn more about LangGraph through our LangGraph Academy course!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T22:07:24.424195Z",
     "start_time": "2025-10-07T22:02:22.476334Z"
    }
   },
   "source": [
    "import nest_asyncio\n",
    "import operator\n",
    "from langchain.schema import Document\n",
    "from langchain_core.messages import HumanMessage, AnyMessage, get_buffer_string\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from utils import get_vector_db_retriever, RAG_PROMPT\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "retriever = get_vector_db_retriever()\n",
    "llm = ChatAnthropic(model_name=\"claude-3-5-haiku-latest\", temperature=0)\n",
    "\n",
    "# Define Graph state\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    messages: Annotated[List[AnyMessage], operator.add]\n",
    "    documents: List[Document]\n",
    "    prev_activities: str\n",
    "\n",
    "# Define Nodes\n",
    "def retrieve_documents(state: GraphState):\n",
    "    messages = state.get(\"messages\", [])\n",
    "    question = state[\"question\"]\n",
    "    prev_activities = state[\"prev_activities\"]\n",
    "    documents = retriever.invoke(f\"{get_buffer_string(messages)} {question} {prev_activities}\")\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "def generate_response(state: GraphState):\n",
    "    question = state[\"question\"]\n",
    "    prev_activities = state[\"prev_activities\"]\n",
    "    messages = state[\"messages\"]\n",
    "    documents = state[\"documents\"]\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    \n",
    "    rag_prompt_formatted = RAG_PROMPT.format(context=formatted_docs, interests=question, prev_activities=prev_activities)\n",
    "    generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "    return {\"documents\": documents, \"messages\": [HumanMessage(question), generation]}\n",
    "\n",
    "# Define Graph\n",
    "graph_builder = StateGraph(GraphState)\n",
    "graph_builder.add_node(\"retrieve_documents\", retrieve_documents)\n",
    "graph_builder.add_node(\"generate_response\", generate_response)\n",
    "graph_builder.add_edge(START, \"retrieve_documents\")\n",
    "graph_builder.add_edge(\"retrieve_documents\", \"generate_response\")\n",
    "graph_builder.add_edge(\"generate_response\", END)\n",
    "\n",
    "simple_rag_graph = graph_builder.compile()\n",
    "display(Image(simple_rag_graph.get_graph().draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manan/PycharmProjects/langsmith-course/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/modules.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x12964aa50>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: 67241b26-34b0-4d6b-b0a7-64ce0d05d941)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/modules.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x129774f50>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: bc7cd496-1e7c-40c3-ac9c-d68fc7f16bcd)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./modules.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/modules.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x129775590>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: ce132daa-2ed2-4dfd-87ff-6deeaf7b930a)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./modules.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/modules.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x129775950>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: 1c227c41-693e-4240-b30a-29c5d2560d29)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./modules.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/modules.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x129775e50>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: a6988892-161b-4514-94fc-20be8075ea2e)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./modules.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/modules.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x129776210>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: 72ee57b9-2e23-45b3-b377-05742076d07e)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./modules.json\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/config_sentence_transformers.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x129776ad0>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: 9bce9980-9541-411f-8a11-923d05e5bcf2)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./config_sentence_transformers.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/config_sentence_transformers.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x129776e90>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: 959fa245-0f1c-489b-9e85-0a744428c651)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./config_sentence_transformers.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/config_sentence_transformers.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x129775d10>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: a88f0bbc-ec5a-4e5c-a502-31f377b83609)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./config_sentence_transformers.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/config_sentence_transformers.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x129777610>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: 2419f8c9-3dad-4790-a4a8-04ce6b7d3307)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./config_sentence_transformers.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/config_sentence_transformers.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x129777250>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: 26fa6300-c7ec-4596-a39a-65432b801fa3)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./config_sentence_transformers.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/config_sentence_transformers.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x129777c50>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: b5354adf-9c1e-4c15-ace4-3da35820f66d)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./config_sentence_transformers.json\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/config_sentence_transformers.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x1297bc410>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: bf6454f0-5880-40f3-8ba8-980875a7fbdd)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./config_sentence_transformers.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/config_sentence_transformers.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x1297765d0>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: dc11d027-58c5-4ba6-beb2-3abd4980c924)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./config_sentence_transformers.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/config_sentence_transformers.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x129777c50>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: 338e1e5f-8238-494a-b327-dd5c841156a4)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./config_sentence_transformers.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-l6-v2/resolve/main/config_sentence_transformers.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x129777250>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: d1653a5e-77c2-4872-8b54-bd1aa7da3511)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-l6-v2/resolve/main/./config_sentence_transformers.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "Fetching pages: 100%|##########| 323/323 [03:16<00:00,  1.64it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're setting up a simple graph in LangGraph. If you want to learn more about LangGraph, I would highly recommend taking a look at our LangGraph Academy course.\n",
    "\n",
    "You can also pass in metadata or other fields through an optional config"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T22:10:15.312145Z",
     "start_time": "2025-10-07T22:10:08.098101Z"
    }
   },
   "source": [
    "interests = \"I have deep interest in medical imaging\"\n",
    "prev_activities = \"Worked on identifying cancer cells using DL and CNNs\"\n",
    "simple_rag_graph.invoke({\"question\": interests, \"prev_activities\": prev_activities}, config={\"metadata\": {\"foo\": \"bar\"}})"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'I have deep interest in medical imaging',\n",
       " 'messages': [HumanMessage(content='I have deep interest in medical imaging', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Based on the context provided, I recommend reaching out to Rajeev Kumar Singh at Shiv Nadar University, who seems to be an excellent match for potential research collaboration. Here's why:\\n\\nAlignment of Research Interests:\\n1. Machine Learning ✓\\n2. Medical Image Computing ✓\\n3. Computer Vision ✓\\n\\nSpecific Evidence of Alignment:\\n- Published multiple papers in medical imaging and deep learning\\n- Specific works include:\\n  - SkiNet: Deep learning framework for skin lesion diagnosis\\n  - COVIDScreen: Explainable deep learning for COVID-19 diagnosis\\n  - DMENet: Diabetic macular edema diagnosis\\n  - CervixNet: Cervical Cancer Diagnosis\\n\\nAdditional Relevance:\\n- Currently an Assistant Professor in Computer Science and Engineering\\n- Has extensive experience in applying deep learning to medical imaging\\n- Published in reputable journals like PLOS ONE and Neural Computing and Applications\\n\\nRecommended Approach:\\n- Highlight your shared interests in medical image computing and machine learning\\n- Reference his specific publications in your email\\n- Express interest in potential research collaboration or guidance\\n\\nThe professor's research profile strongly aligns with your research interests, making him an ideal potential research mentor or collaborator.\", additional_kwargs={}, response_metadata={'id': 'msg_01MXYseMxApqSwbCkNJtdGXP', 'model': 'claude-3-5-haiku-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1075, 'output_tokens': 279, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-5-haiku-20241022'}, id='run--53004a3d-4998-4c4a-a4e3-f1c06d87c154-0', usage_metadata={'input_tokens': 1075, 'output_tokens': 279, 'total_tokens': 1354, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})],\n",
       " 'documents': [Document(metadata={'id': '7e70f120-099b-4be6-92f1-1f08a796291d', 'source': 'https://snu.edu.in/faculty/nitin-kumar/', 'loc': 'https://snu.edu.in/faculty/nitin-kumar/', 'lastmod': '2025-08-20T06:28:00+00:00', 'changefreq': 'monthly', 'priority': '0.5'}, page_content='Research Interest                                                    \\n\\n\\n\\n\\nMachine Learning\\nMedical Image Computing\\nComputer Vision\\nGraph Representation Learning\\n\\nTo learn more about my work, visit:\\xa0https://nitinnazkani.github.io/nitinnazkani/\\n\\xa0 \\n\\n\\n\\n\\n\\n                                                                National and International Recognition                                                    \\n\\n\\n\\n\\nIn top 10 (0.3%) finalists for best paper award at IEEE International Conference on Image Processing (ICIP) -2017\\nRecipient of travel grants from MICCAI, ICIP, MedImage societies\\n \\n\\n\\n\\n\\n\\n                                                                Academic Achievements'),\n",
       "  Document(metadata={'id': 'ac2b844b-1eb8-409e-b46c-00d012abadbd', 'source': 'https://snu.edu.in/faculty/rajeev-kumar-singh/', 'loc': 'https://snu.edu.in/faculty/rajeev-kumar-singh/', 'lastmod': '2025-08-20T06:22:59+00:00', 'changefreq': 'monthly', 'priority': '0.5'}, page_content='1. Rajeev Kumar Singh, Rohan Gorantla, Sai Giridhar Rao Allada, Pratap Narra SkiNet: A deep learning framework for skin lesion diagnosis with uncertainty estimation and explainability Plos one 17 2022.\\n2. Rajeev Kumar Singh, Rohan Pandey, Rishie Nandhan Babu COVIDScreen: explainable deep learning framework for differential diagnosis of COVID-19 using chest X-rays Neural Computing and Applications 33 2021.\\n3. Rajeev Kumar Singh, Sonia Khetarpaul, Rohan Gorantla, Sai Giridhar Allada SHEG: summarization and headline generation of news articles using deep learning Neural Computing and Applications 33 2021.\\n4. Rajeev Kumar Singh, Rohan Gorantla DMENet: diabetic macular edema diagnosis using hierarchical ensemble of CNNs Plos one 15 2020.\\n5. Gorantla Rohan, Singh Rajeev Kumar, Pandey Rohan, Jain Mayank Cervical Cancer Diagnosis using CervixNet - A Deep Learning Approach Publisher: IEEE 2019.\\n6. Santosh Kumar, Rajeev Kumar Singh, Karmeshu Exact distributions for bit error rate and channel capacity in free-space optical communication IET communications 13 2019.\\n7. Rajeev Kumar Singh, Santosh Kumar, Karmeshu A New Approximation for PDF of K Distribution: Analytical Study of QoS Parameters in Free Space Optical Communication IET communications 2018.\\n8. Rajeev Kumar Singh Exact analytical BER expression in FSO using ?-? distribution proposed as an approximation of gamma-gamma PDF Publisher: IEEE 2018.\\n9. Rajeev Kumar Singh, Santosh Kumar A novel approximation for k distribution: Closed-form ber using dpsk modulation in free-space optical communication IEEE Photonics Journal 9 2017.\\n10. Tarun Kumar, Rajeev Kumar Singh Analysis of compiler optimization techniques by using feature mining technique \"Publisher IEEE\" 2015. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\n\\n\\nAbout\\n\\n\\nResearch\\n\\n\\nPrograms\\n\\n\\nAdmissions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFaculty\\n\\n\\nSchools and Centers\\n\\n\\nOmbudsperson\\n\\n\\nThe Office of the Registrar\\n\\n\\nNews\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEvents\\n\\n\\nCareers\\n\\n\\nAlumni'),\n",
       "  Document(metadata={'id': 'b86aced9-db40-44fb-9c97-87094a50fd4b', 'source': 'https://snu.edu.in/faculty/pooja-malik/', 'loc': 'https://snu.edu.in/faculty/pooja-malik/', 'lastmod': '2025-08-20T06:22:59+00:00', 'changefreq': 'monthly', 'priority': '0.5'}, page_content='Work Experience                                                    \\n\\n\\n\\n08/15-Present, Assistant Professor, Department of Computer Science and Engineering, School of Engineering, Shiv Nadar University, Delhi NCR\\n02/13-07/15, Assistant Professor, Noida International University, Greater Noida\\n07/11-01/13, Assistant Professor, Mangalmay Institute of Engineering and Technology, Greater Noida \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                                                Journal Publications                                                    \\n\\n\\n\\n\\nGaurav Dubey, Somya Srivastava, Anant Kumar Jayswal, Mala Saraswat, Pooja Singh, Minakshi Memoria, “Fetal Ultrasound Segmentation and Measurements Using Appearance and Shape Prior Based Density Regression with Deep CNN and Robust Ellipse Fitting”, Journal of Imaging Informatics in Medicine, 2024, Springer International Publishing. DOI: https://doi.org/10.1007/s10278-023-00908-8.'),\n",
       "  Document(metadata={'id': '2fd922c6-d321-4ab1-9f3a-271dde9c40b2', 'source': 'https://snu.edu.in/faculty/snehasis_mukherjee/', 'loc': 'https://snu.edu.in/faculty/snehasis_mukherjee/', 'lastmod': '2025-08-20T06:27:57+00:00', 'changefreq': 'monthly', 'priority': '0.5'}, page_content='Research interest                                                    \\n\\n\\n\\nMachine Learning and Computer Vision\\nLink to lab webpage:\\xa0https://sites.google.com/site/snehasisisi/home\\n\\nKnow more: Click here \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                                                Journal Publication')],\n",
       " 'prev_activities': 'Worked on identifying cancer cells using DL and CNNs'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's take a look in LangSmith!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing Context Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, you can use the trace context manager to log traces to LangSmith. This is useful in situations where:\n",
    "\n",
    "You want to log traces for a specific block of code.\n",
    "You want control over the inputs, outputs, and other attributes of the trace.\n",
    "It is not feasible to use a decorator or wrapper.\n",
    "Any or all of the above.\n",
    "The context manager integrates seamlessly with the traceable decorator and wrap_openai wrapper, so you can use them together in the same application.\n",
    "\n",
    "You still need to set your `LANGSMITH_API_KEY` and `LANGSMITH_TRACING`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T22:10:29.706311Z",
     "start_time": "2025-10-07T22:10:20.524465Z"
    }
   },
   "source": [
    "from langsmith import traceable, trace\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "MODEL_PROVIDER = \"anthropic\"\n",
    "MODEL_NAME = \"claude-3-5-haiku-latest\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "anthropic_client = Anthropic()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "\"\"\"\n",
    "retrieve_documents\n",
    "- Returns documents fetched from a vectorstore based on the user's question\n",
    "\"\"\"\n",
    "@traceable\n",
    "def retrieve_documents(question: str):\n",
    "    documents = retriever.invoke(question)\n",
    "    return documents\n",
    "\n",
    "\"\"\"\n",
    "generate_response\n",
    "- Calls `call_anthropic` to generate a model response after formatting inputs\n",
    "\"\"\"\n",
    "\n",
    "def generate_response(question: str, documents):\n",
    "    # NOTE: Our documents came in as a list of objects, but we just want to log a string\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "    with trace(\n",
    "        name=\"Generate Response\",\n",
    "        run_type=\"chain\",\n",
    "        inputs={\"question\": question, \"formatted_docs\": formatted_docs},\n",
    "        metadata={\"foo\": \"bar\"},\n",
    "    ) as ls_trace:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"To the most suitable professor, write a mail for research opportunities. Context: {formatted_docs} \\n\\n Interests: {question}\"\n",
    "            }\n",
    "        ]\n",
    "        response = call_claude(messages, RAG_SYSTEM_PROMPT)\n",
    "        ls_trace.end(outputs={\"output\": response})\n",
    "    return response\n",
    "\n",
    "\"\"\"\n",
    "call_claude\n",
    "- Returns the chat completion output from OpenAI\n",
    "\"\"\"\n",
    "@traceable\n",
    "def call_claude(\n",
    "    messages: List[dict], system: str, model: str = MODEL_NAME, temperature: float = 0.0\n",
    ") -> str:\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=model,\n",
    "        system=system,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\"\"\"\n",
    "langsmith_rag\n",
    "- Calls `retrieve_documents` to fetch documents\n",
    "- Calls `generate_response` to generate a response based on the fetched documents\n",
    "- Returns the model response\n",
    "\"\"\"\n",
    "@traceable\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.content[0].text\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T22:10:33.755764Z",
     "start_time": "2025-10-07T22:10:29.713741Z"
    }
   },
   "source": [
    "interests = \"Interest in Natural Language Processing and Machine Translation\"\n",
    "ai_answer = langsmith_rag(interests)\n",
    "print(ai_answer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a draft email for research opportunities:\n",
      "\n",
      "Subject: Research Collaboration Inquiry in Natural Language Processing and Machine Translation\n",
      "\n",
      "Dear Professor,\n",
      "\n",
      "I am writing to express my strong interest in potential research opportunities in Natural Language Processing, particularly focusing on Machine Translation for Indian languages. Given my background in publishing research on machine translation evaluation metrics and my experience presenting at conferences like ICON 2021, I am eager to explore collaborative research possibilities in your department.\n",
      "\n",
      "Would you be available to discuss potential research projects or assistantships that align with your current work in NLP?\n",
      "\n",
      "Sincerely,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wrap_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrap_openai/wrapOpenAI methods in Python/TypeScript allow you to wrap your OpenAI client in order to automatically log traces -- no decorator or function wrapping required! The wrapper works seamlessly with the @traceable decorator or traceable function and you can use both in the same application.\n",
    "\n",
    "You still need to set your `LANGSMITH_API_KEY` and `LANGSMITH_TRACING`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T22:14:49.187130Z",
     "start_time": "2025-10-07T22:14:40.753495Z"
    }
   },
   "source": [
    "from langsmith.wrappers import wrap_anthropic\n",
    "import anthropic\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "MODEL_PROVIDER = \"anthropic\"\n",
    "MODEL_NAME = \"claude-3-5-haiku-latest\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "anthropic_client = wrap_anthropic(anthropic.Client())\n",
    "\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    return anthropic_client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag_with_wrap_openai(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.content[0].text\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T22:14:57.138398Z",
     "start_time": "2025-10-07T22:14:53.213813Z"
    }
   },
   "source": [
    "question = \"How do I trace with wrap_openai?\"\n",
    "ai_answer = langsmith_rag_with_wrap_openai(question)\n",
    "print(ai_answer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but I cannot find any information in the provided context about \"wrap_openai\" or tracing. The context appears to be about a research grant for developing a catalytic membrane for tannery effluent treatment, along with some details about the Shiv Nadar Institution of Eminence and some research publications. \n",
      "\n",
      "If you're looking for information about tracing with wrap_openai, you would need to provide more context or specific details about what you're trying to accomplish. Without additional information, I cannot provide a meaningful answer about tracing with wrap_openai.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapped OpenAI client accepts all the same langsmith_extra parameters as @traceable decorated functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T22:16:23.752295Z",
     "start_time": "2025-10-07T22:16:20.918526Z"
    }
   },
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What color is the sky?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "anthropic_client.messages.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=messages,\n",
    "    langsmith_extra={\"metadata\": {\"foo\": \"bar\"}},\n",
    "    max_tokens=1024,\n",
    "    temperature=0\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_01Qu6zLZZjrwLC2143oovw2N', content=[TextBlock(citations=None, text=\"The sky is typically blue during clear daytime conditions. The blue color is caused by a phenomenon called Rayleigh scattering, where sunlight is scattered by molecules in the Earth's atmosphere. During sunrise and sunset, the sky can appear orange, red, or pink due to the angle of sunlight. At night, the sky appears dark or black.\", type='text')], model='claude-3-5-haiku-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation=CacheCreation(ephemeral_1h_input_tokens=0, ephemeral_5m_input_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=13, output_tokens=77, server_tool_use=None, service_tier='standard'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## [Advanced] RunTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another, more explicit way to log traces to LangSmith is via the RunTree API. This API allows you more control over your tracing - you can manually create runs and children runs to assemble your trace. You still need to set your `LANGSMITH_API_KEY`, but `LANGSMITH_TRACING` is not necessary for this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AWTT](../../images/alternative_ways_to_trace_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# I have my env variables defined in a .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and set `LANGSMITH_TRACING` to false, as we are using RunTree to manually create runs in this case."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T22:25:04.057663Z",
     "start_time": "2025-10-07T22:25:04.050161Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"false\"\n",
    "\n",
    "from langsmith import utils\n",
    "utils.tracing_is_enabled() # This should return false"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have rewritten our RAG application, except this time we pass a RunTree argument through our function calls, and create child runs at each layer. This gives our RunTree the same hierarchy that we were automatically able to establish with @traceable"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T22:34:07.895919Z",
     "start_time": "2025-10-07T22:33:58.891947Z"
    }
   },
   "source": [
    "from langsmith import RunTree\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "anthropic_client = Anthropic()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "def retrieve_documents(parent_run: RunTree, question: str):\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"Retrieve Documents\",\n",
    "        run_type=\"retriever\",\n",
    "        inputs={\"question\": question},\n",
    "    )\n",
    "    documents = retriever.invoke(question)\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"documents\": documents})\n",
    "    child_run.post()\n",
    "    return documents\n",
    "\n",
    "def generate_response(parent_run: RunTree, question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    rag_system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise.\n",
    "    \"\"\"\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"Generate Response\",\n",
    "        run_type=\"chain\",\n",
    "        inputs={\"question\": question, \"documents\": documents},\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    claude_response = call_anthropic(child_run, messages, rag_system_prompt)\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"claude_response\": claude_response})\n",
    "    child_run.post()\n",
    "    return claude_response\n",
    "\n",
    "def call_anthropic(\n",
    "    parent_run: RunTree, messages: List[dict], rag_system_prompt: str, model: str = \"claude-3-5-haiku-latest\", temperature: float = 0.0\n",
    ") -> str:\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"Claude Call\",\n",
    "        run_type=\"llm\",\n",
    "        inputs={\"messages\": messages},\n",
    "    )\n",
    "    claude_response = anthropic_client.messages.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        system=rag_system_prompt,\n",
    "        temperature=temperature,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"claude_response\": claude_response})\n",
    "    child_run.post()\n",
    "    return claude_response\n",
    "\n",
    "def langsmith_rag(question: str):\n",
    "    # Create a root RunTree\n",
    "    root_run_tree = RunTree(\n",
    "        name=\"Chat Pipeline\",\n",
    "        run_type=\"chain\",\n",
    "        inputs={\"question\": question}\n",
    "    )\n",
    "\n",
    "    # Pass our RunTree into the nested function calls\n",
    "    documents = retrieve_documents(root_run_tree, question)\n",
    "    response = generate_response(root_run_tree, question, documents)\n",
    "    output = response.content[0].text\n",
    "\n",
    "    # Post our final output\n",
    "    root_run_tree.end(outputs={\"generation\": output})\n",
    "    root_run_tree.post()\n",
    "    return output\n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T22:34:10.570819Z",
     "start_time": "2025-10-07T22:34:07.904825Z"
    }
   },
   "source": [
    "question = \"What are the interests of professors in math department here?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "print(ai_answer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, the professors in the mathematics department have expertise in:\n",
      "\n",
      "1. Analysis\n",
      "2. Algebra and Number Theory\n",
      "\n",
      "These are the specific areas of mathematical interest mentioned in the work experience and area of expertise sections. The context shows at least one professor has worked in these domains at the School of Natural Sciences, Shiv Nadar University.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ls-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
